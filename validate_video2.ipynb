{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../applied-machine-learning/video2.yaml, weights=['../yolov5/runs/train/PP3_small2/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=cpu, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=False, save_json=False, project=../yolov5/runs/val, name=video2_PP3_small2, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.1-14-g8a66eba torch 1.10.2+cu102 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/sergio/Projects/Doutorado/ML/datasets/video2/labels/valid.c\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        291        291      0.596      0.701      0.667      0.332\n",
      "                 cat        291        291      0.596      0.701      0.667      0.332\n",
      "Speed: 1.0ms pre-process, 79.3ms inference, 0.9ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov5/runs/val/video2_PP3_small2\u001b[0m\n",
      "291 labels saved to ../yolov5/runs/val/video2_PP3_small2/labels\n"
     ]
    }
   ],
   "source": [
    "# validate video2 - PP3_small2\n",
    "!python3 ../yolov5/val.py --weights ../yolov5/runs/train/PP3_small2/weights/best.pt --data ../applied-machine-learning/video2.yaml --verbose --device cpu --name \"video2_PP3_small2\" --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../applied-machine-learning/video2.yaml, weights=['../yolov5/runs/train/PP3_small3/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=cpu, workers=8, single_cls=True, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=False, save_json=False, project=../yolov5/runs/val, name=video2_PP3_small3, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.1-14-g8a66eba torch 1.10.2+cu102 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/sergio/Projects/Doutorado/ML/datasets/video2/labels/valid.c\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        291        291      0.959      0.808      0.941      0.514\n",
      "Speed: 1.0ms pre-process, 78.5ms inference, 0.8ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov5/runs/val/video2_PP3_small3\u001b[0m\n",
      "291 labels saved to ../yolov5/runs/val/video2_PP3_small3/labels\n"
     ]
    }
   ],
   "source": [
    "# validate video2 - PP3_small3 -> SINGLE CLASS\n",
    "!python3 ../yolov5/val.py --weights ../yolov5/runs/train/PP3_small3/weights/best.pt --data ../applied-machine-learning/video2.yaml --verbose --device cpu --name \"video2_PP3_small3\" --save-txt --single-cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../applied-machine-learning/video2.yaml, weights=['../yolov5/runs/train/PP6/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=cpu, workers=8, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=../yolov5/runs/val, name=video2_PP6, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.1-14-g8a66eba torch 1.10.2+cu102 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/sergio/Projects/Doutorado/ML/datasets/video2/labels/valid.c\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        291        291      0.834      0.726      0.834      0.328\n",
      "                 cat        291        291      0.834      0.726      0.834      0.328\n",
      "Speed: 0.9ms pre-process, 79.5ms inference, 1.8ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov5/runs/val/video2_PP6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# validate video2 - PP6\n",
    "!python3 ../yolov5/val.py --weights ../yolov5/runs/train/PP6/weights/best.pt --data ../applied-machine-learning/video2.yaml --verbose --device cpu --name \"video2_PP6\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
