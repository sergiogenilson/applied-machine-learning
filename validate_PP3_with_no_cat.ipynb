{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../applied-machine-learning/no_cat.yaml, weights=['../yolov5/runs/train/PP3_m4/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=cpu, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=False, save_json=False, project=../yolov5/runs/val, name=no_cat_PP3_m, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.1-14-g8a66eba torch 1.10.2+cu102 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 290 layers, 20861016 parameters, 0 gradients, 48.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/sergio/Projects/Doutorado/ML/datasets/no_cat/labels/valid' \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/sergio/Projects/Doutorado/ML/datasets/no_cat/labels/valid.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all         32         33      0.238      0.513      0.176      0.121\n",
      "              person         32          1      0.332      0.996      0.332      0.232\n",
      "                 cat         32         32      0.145     0.0312     0.0201     0.0105\n",
      "Speed: 3.0ms pre-process, 369.7ms inference, 0.8ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov5/runs/val/no_cat_PP3_m\u001b[0m\n",
      "32 labels saved to ../yolov5/runs/val/no_cat_PP3_m/labels\n"
     ]
    }
   ],
   "source": [
    "# validate no_cat - PP3_m\n",
    "!python3 ../yolov5/val.py --weights ../yolov5/runs/train/PP3_m4/weights/best.pt --data ../applied-machine-learning/no_cat.yaml --verbose --name \"no_cat_PP3_m\" --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../yolov5/runs/train/PP3_m4/weights/best.pt'], source=../datasets/no_cat/images/valid, data=../yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=../yolov5/runs/detect, name=no_cat_PP3_m, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.1-14-g8a66eba torch 1.10.2+cu102 CUDA:0 (NVIDIA GeForce GTX 1650, 3912MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 290 layers, 20861016 parameters, 0 gradients, 48.0 GFLOPs\n",
      "image 1/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FH-DWoNWQAMxAbY.jpeg: 640x480 Done. (0.036s)\n",
      "image 2/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FH2zgN-WUAkN8cN.jpeg: 640x384 Done. (0.023s)\n",
      "image 3/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FH8a6GBX0Ag5NcK.jpeg: 640x480 1 cat, Done. (0.030s)\n",
      "image 4/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FHv57xKWUAgw-9v.jpeg: 640x480 Done. (0.030s)\n",
      "image 5/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FHykSbyXoAAIZ7c.jpeg: 640x480 1 person, Done. (0.030s)\n",
      "image 6/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FI1PgQvX0Ag7EPw.jpeg: 640x480 2 dogs, Done. (0.031s)\n",
      "image 7/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIAtDAtXwAQsFQd.jpeg: 640x512 Done. (0.030s)\n",
      "image 8/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIB97y0VgAQThQR.jpeg: 640x384 Done. (0.023s)\n",
      "image 9/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIHExInWUA8VTsW.jpeg: 640x480 Done. (0.030s)\n",
      "image 10/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIL4agOXEAAyVxQ.jpeg: 640x480 Done. (0.030s)\n",
      "image 11/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FINIO9UX0AE81hA.jpeg: 480x640 Done. (0.027s)\n",
      "image 12/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIVto-bWYAUC6wY.jpeg: 640x480 Done. (0.031s)\n",
      "image 13/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIWPw7hWYAMwyJX.jpeg: 384x640 1 cat, Done. (0.024s)\n",
      "image 14/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIYKPIEWYAIa3SR.jpeg: 640x480 1 cat, Done. (0.030s)\n",
      "image 15/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIgdCFiXwAI08tp.jpeg: 640x480 Done. (0.031s)\n",
      "image 16/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIhAyurWYAMW23v.jpeg: 640x480 1 person, Done. (0.028s)\n",
      "image 17/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FIhDBwTXwAM7S5t.jpeg: 640x480 Done. (0.029s)\n",
      "image 18/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FJ9183JX0AA0uao.jpeg: 640x480 Done. (0.029s)\n",
      "image 19/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FJeJfveXwAIAgBN.jpeg: 608x640 1 person, Done. (0.037s)\n",
      "image 20/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FJuzmpDWQAYR1Ak.jpeg: 640x480 Done. (0.027s)\n",
      "image 21/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FJyW6JuXEAIiyIf.jpeg: 640x448 Done. (0.026s)\n",
      "image 22/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FK3x_eAWUAEPrcQ.jpeg: 480x640 Done. (0.029s)\n",
      "image 23/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FK872vWWYAUK1Ge.jpeg: 480x640 Done. (0.027s)\n",
      "image 24/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FKDxf1BXoAI2OaN.jpeg: 480x640 Done. (0.027s)\n",
      "image 25/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FKHooPDUcBY4bPT.jpeg: 640x480 Done. (0.029s)\n",
      "image 26/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FKS3DKrXIAkw11B.jpeg: 640x480 Done. (0.031s)\n",
      "image 27/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FKdd5niWQAIZRJK.jpeg: 640x512 Done. (0.027s)\n",
      "image 28/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FKi84E7XEAg137N.jpeg: 640x480 Done. (0.029s)\n",
      "image 29/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FKq-55cXsAEEoIg.jpeg: 480x640 Done. (0.029s)\n",
      "image 30/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FKxLzkXWUAg3C9K.jpeg: 640x384 Done. (0.023s)\n",
      "image 31/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FKyZE3MXEAEdzed.jpeg: 640x480 Done. (0.028s)\n",
      "image 32/32 /home/sergio/Projects/Doutorado/ML/datasets/no_cat/images/valid/FLA7u9QWQAEd8wt.jpeg: 640x480 Done. (0.026s)\n",
      "Speed: 0.5ms pre-process, 28.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m../yolov5/runs/detect/no_cat_PP3_m2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# detect no_cat - PP3_m\n",
    "!python3 ../yolov5/detect.py --weights ../yolov5/runs/train/PP3_m4/weights/best.pt --source ../datasets/no_cat/images/valid --name \"no_cat_PP3_m\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
