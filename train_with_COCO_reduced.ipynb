{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/home/sergio/fiftyone/coco-2017/train' if necessary\n",
      "Found annotations at '/home/sergio/fiftyone/coco-2017/raw/instances_train2017.json'\n",
      "Sufficient images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading 'coco-2017' split 'train'\n",
      "  11% |‚ñà/-----------|  7346/69713 [38.5s elapsed, 5.4m remaining, 231.4 samples/s]   "
     ]
    }
   ],
   "source": [
    "\n",
    "train = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"train\",\n",
    "    label_types=[\"detections\"],\n",
    "    classes=[\"person\", \"cat\", \"dog\"],\n",
    "    # max_samples=200 # remove limitations if project is working\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'test' to '/home/sergio/fiftyone/coco-2017/test' if necessary\n",
      "Test split is unlabeled; ignoring classes requirement\n",
      "Found test info at '/home/sergio/fiftyone/coco-2017/raw/image_info_test2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'test' is sufficient\n",
      "Loading 'coco-2017' split 'test'\n",
      "Dataset is unlabeled; ignoring classes requirement\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40670/40670 [11.8s elapsed, 0s remaining, 3.2K samples/s]      \n",
      "Dataset 'coco-2017-test' created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"test\",\n",
    "    label_types=[\"detections\"],\n",
    "    classes=[\"person\", \"cat\", \"dog\"],\n",
    "    # max_samples=100 # remove limitations if project is working\n",
    ")\n",
    "\n",
    "# Look at the data\n",
    "# session = fo.launch_app(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/home/sergio/fiftyone/coco-2017/validation' if necessary\n",
      "Found annotations at '/home/sergio/fiftyone/coco-2017/raw/instances_val2017.json'\n",
      "Sufficient images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2945/2945 [14.7s elapsed, 0s remaining, 200.5 samples/s]      \n",
      "Dataset 'coco-2017-validation' created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"detections\"],\n",
    "    classes=[\"person\", \"cat\", \"dog\"],\n",
    "    # max_samples=100 # remove limitations if project is working\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = \"../datasets/COCO_REDUC_PP\"\n",
    "label_field = \"ground_truth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../datasets/COCO_REDUC_PP' already exists; export will be merged with existing files\n",
      "   2% |\\--------------|   67/2945 [329.9ms elapsed, 14.2s remaining, 203.1 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.8/site-packages/fiftyone/utils/yolo.py:994: UserWarning: Ignoring detection with label 'toilet' not in provided classes\n",
      "  warnings.warn(msg)\n",
      "/home/sergio/.local/lib/python3.8/site-packages/fiftyone/utils/yolo.py:994: UserWarning: Ignoring detection with label 'sheep' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3% ||--------------|   90/2945 [431.7ms elapsed, 13.7s remaining, 208.5 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.8/site-packages/fiftyone/utils/yolo.py:994: UserWarning: Ignoring detection with label 'apple' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7% |/--------------|  195/2945 [1.1s elapsed, 15.7s remaining, 175.7 samples/s]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.8/site-packages/fiftyone/utils/yolo.py:994: UserWarning: Ignoring detection with label 'zebra' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  32% |‚ñà‚ñà‚ñà‚ñà\\----------|  937/2945 [4.2s elapsed, 9.0s remaining, 218.5 samples/s]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.8/site-packages/fiftyone/utils/yolo.py:994: UserWarning: Ignoring detection with label 'toaster' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  46% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|--------| 1364/2945 [5.9s elapsed, 6.7s remaining, 241.6 samples/s]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.8/site-packages/fiftyone/utils/yolo.py:994: UserWarning: Ignoring detection with label 'hair drier' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  60% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|------| 1760/2945 [7.6s elapsed, 5.0s remaining, 243.6 samples/s]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.8/site-packages/fiftyone/utils/yolo.py:994: UserWarning: Ignoring detection with label 'bear' not in provided classes\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2945/2945 [12.1s elapsed, 0s remaining, 265.7 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "validation.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=label_field,\n",
    "    classes=[\"person\", \"cat\", \"dog\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../datasets/COCO_REDUC_PP' already exists; export will be merged with existing files\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40670/40670 [33.3s elapsed, 0s remaining, 1.3K samples/s]      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "test.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=label_field,\n",
    "    split=\"test\",\n",
    "    classes=[\"person\", \"cat\", \"dog\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../datasets/COCO_REDUC_PP' already exists; export will be merged with existing files\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69713/69713 [4.7m elapsed, 0s remaining, 242.8 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "train.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=label_field,\n",
    "    split=\"train\",\n",
    "    classes=[\"person\", \"cat\", \"dog\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- TRAIN ----\n",
      "Persons:  262465\n",
      "Cats:  4768\n",
      "Dogs:  5508\n",
      " ---- TEST ----\n",
      "Persons:  0\n",
      "Cats:  0\n",
      "Dogs:  0\n",
      " ---- VALIDATION ----\n",
      "Persons:  11004\n",
      "Cats:  202\n",
      "Dogs:  218\n"
     ]
    }
   ],
   "source": [
    "# Count itens from each class\n",
    "\n",
    "import glob\n",
    "\n",
    "export_dir = \"../datasets/COCO_REDUC_PP\"\n",
    "\n",
    "person = \"0\"\n",
    "cat = \"1\"\n",
    "dog = \"2\"\n",
    "\n",
    "def count_classes(dir):\n",
    "    persons = 0\n",
    "    cats = 0\n",
    "    dogs = 0\n",
    "    for file in glob.glob(dir + \"*.txt\"):\n",
    "        with open(file) as f:\n",
    "            for line in f:\n",
    "                s = line.split(\" \", 1)\n",
    "                if s[0] == person:\n",
    "                    persons += 1\n",
    "                elif s[0] == cat:\n",
    "                    cats += 1\n",
    "                elif s[0] == dog:\n",
    "                    dogs += 1\n",
    "            f.close()\n",
    "    print(\"Persons: \", persons)\n",
    "    print(\"Cats: \", cats)\n",
    "    print(\"Dogs: \", dogs)\n",
    "    return [persons, cats, dogs]\n",
    "\n",
    "\n",
    "train_dir = export_dir + \"/labels/train/\"\n",
    "test_dir = export_dir + \"/labels/test/\"\n",
    "validation_dir = export_dir + \"/labels/val/\"\n",
    "\n",
    "print(\" ---- TRAIN ----\")\n",
    "train_counts = count_classes(train_dir)\n",
    "\n",
    "print(\" ---- TEST ----\")\n",
    "test_counts = count_classes(test_dir)\n",
    "\n",
    "print(\" ---- VALIDATION ----\")\n",
    "validation_counts = count_classes(validation_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove persons\n",
    "import random, os\n",
    "\n",
    "def remove_persons_excess(labels_dir, images_dir, persons, others):\n",
    "    print (\"----> \" + str(persons) + \" persons and others \" + str(others) + \" objects\")\n",
    "    without_persons_count = 0\n",
    "    files = glob.glob(labels_dir + \"*.txt\")\n",
    "    while persons > others:\n",
    "        file = random.choice(files)\n",
    "        name = file.split('/')\n",
    "        filename = name[-1].split('.')\n",
    "        img = images_dir + filename[0] + \".jpg\"\n",
    "        p = 0\n",
    "        o = 0\n",
    "        with open(file) as f:\n",
    "            for line in f: \n",
    "                s = line.split(\" \", 1)\n",
    "                if s[0] == person:\n",
    "                    p += 1\n",
    "                else:\n",
    "                    o += 1\n",
    "            f.close()\n",
    "        if p > 0 and o == 0: # have persons, but no cat and dogs\n",
    "            try:\n",
    "                os.remove(file)\n",
    "                os.remove(img)\n",
    "                persons -= p\n",
    "                without_persons_count = 0\n",
    "                files.remove(file)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", file)\n",
    "        else:\n",
    "            without_persons_count += 1\n",
    "            if without_persons_count > 100: # prevent running for ever, if no files to delete\n",
    "                print(\"-------------> Emergency stop....\")\n",
    "                break\n",
    "        print(\"Files in dir: \", len(files), end=\"\\r\")\n",
    "    print(\"---------------------> REMOVE PERSONS FINISHED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persons:  11004\n",
      "Cats:  202\n",
      "Dogs:  218\n",
      "----> 11004 persons and others 420 objects\n",
      "Persons:  419  3810\n",
      "Cats:  202\n",
      "Dogs:  218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[419, 202, 218]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_counts = count_classes(validation_dir)\n",
    "remove_persons_excess(validation_dir, export_dir + \"/images/val/\", validation_counts[0], validation_counts[1] + validation_counts[2])\n",
    "count_classes(validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persons:  262465\n",
      "Cats:  4768\n",
      "Dogs:  5508\n",
      "----> 262465 persons and others 10276 objects\n",
      "---------------------> REMOVE PERSONS FINISHED\n",
      "Persons:  10274\n",
      "Cats:  4768\n",
      "Dogs:  5508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10274, 4768, 5508]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = count_classes(train_dir)\n",
    "remove_persons_excess(train_dir, export_dir + \"/images/train/\", train_counts[0], train_counts[1] + train_counts[2])\n",
    "count_classes(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=../yolov5/yolov5s.pt, cfg=../yolov5/models/yolov5s.yaml, data=../applied-machine-learning/coco_pp_reduc.yaml, hyp=../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../yolov5/runs/train, name=COCO_PP_REDUC, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 40 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.1-14-g8a66eba torch 1.10.2+cu102 CUDA:0 (NVIDIA GeForce GTX 1650, 3912MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../yolov5/runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from ../yolov5/yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/sergio/Projects/Doutorado/ML/datasets/COCO_REDUC_PP/label\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/sergio/Projects/Doutorado/ML/datasets/COCO_REDUC_PP/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/sergio/Projects/Doutorado/ML/datasets/COCO_REDUC_PP/labels/\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/sergio/Projects/Doutorado/ML/datasets/COCO_REDUC_PP/labels/val.cache\n",
      "Plotting labels to ../yolov5/runs/train/COCO_PP_REDUC2/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.14 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m../yolov5/runs/train/COCO_PP_REDUC2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/99     1.73G   0.06404   0.03246   0.02203        25       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        381        839      0.703      0.609      0.669      0.371\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/99     1.62G    0.0483   0.02801   0.01416        20       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        381        839      0.707      0.582      0.661      0.374\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/99     1.63G   0.04368   0.03134   0.01422        36       640:   1%|   ^C\n"
     ]
    }
   ],
   "source": [
    "# train yolo with PP dataset in COCO format\n",
    "!python3 ../yolov5/train.py --img 640 --batch 8 --epochs 100 --data ../applied-machine-learning/coco_pp_reduc.yaml --cfg ../yolov5/models/yolov5s.yaml --name COCO_PP_REDUC"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e55666fbbf217aa3df372b978577f47b6009e2f78e2ec76a584f49cd54a1e62c"
  },
  "kernelspec": {
   "display_name": "Python 2.7.18 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
